---
lab:
    title: 'Language サービスによる言語理解モデルの作成 (プレビュー)'
---

# Language サービスによる言語理解モデルの作成 (プレビュー)

> **注**: Language サービスの会話型言語理解機能は、現在プレビュー段階であり、変更される可能性があります。場合によっては、モデル トレーニングに失敗することがあります。その場合はもう一度お試しください。  

Language サービスを使用すると、ユーザーからの自然言語入力の解釈、ユーザーの*意図* (達成したいこと) の予測、意図を適用する必要がある*エンティティ*の特定を行うためにアプリケーションが使用できる*会話型言語理解*モデルを定義できます。

たとえば、時計アプリケーション用の言語理解モデルは、次のような入力を処理することが期待される場合があります。

*What is the time in London?*

この種の入力は、*発話* (ユーザーが言うまたは入力する可能性のあるもの) の例です。特定の場所 (*エンティティ*) で時間を取得することが*意図*です。この場合、場所は London です。

> **注**: 言語理解モデルのタスクは、ユーザーの意図を予測し、意図が適用されるエンティティを特定することです。意図を満たすために必要なアクションを実際に実行することは、このモデルの役割では<u>ありません</u>。たとえば、時計アプリケーションは言語アプリを使用して、ユーザーがロンドンの時刻を知りたいことを識別できます。ただし、クライアント アプリケーション自体は、正しい時刻を決定してユーザーに提示するロジックを実装する必要があります。

## Language サービスのリソースを作成する

会話型言語理解モデルを作成するには、サポートされているリージョンの **Language サービス** リソースが必要です。本項執筆時点でサポートされているリージョンは、米国西部 2 と西ヨーロッパのみです。

1. `https://portal.azure.com` で Azure portal を開き、Azure サブスクリプションに関連付けられている Microsoft アカウントを使用してサインインします。
2. 「**&#65291;Create a resource**」 (リソースの作成) ボタンを選択し、*language* を検索して、次の設定で **Language service** リソースを作成します。

    - **サブスクリプション**: *使用する Azure サブスクリプション*
    - **リソース グループ**: *リソース グループを選択または作成します (制限付きサブスクリプションを使用している場合は、新しいリソース グループを作成する権限がない可能性があります - 提供されているものを使用してください)*
    - **リージョン**: 米国西部 2 または西ヨーロッパ
    - **名前**: *一意の名前を入力します*
    - **価格レベル**: 無料 (F0) (*このレベルが利用できない場合は、Standard (S) を選択します*)
    - **法律条項**：_同意_ 
    - **責任ある AI に関する通知**：_同意_
3. デプロイが完了するのを待ってから、デプロイの詳細を表示します。

## 会話型言語理解プロジェクトを作成する

オーサリング リソースを作成したので、それを使用して会話型言語理解プロジェクトを作成できます。

1. 新しいブラウザー タブで、`https://language.azure.com` の Language Studio ポータルを開き、Azure サブスクリプションに関連付けられている Microsoft アカウントを使用してサインインします。
2. 言語リソースの選択を求められたら、次の設定を選択します。
    - **Azure ディレクトリ**: サブスクリプションを含む Azure ディレクトリ。
    - **Azure サブスクリプション**: Azure サブスクリプション。
    - **言語リソース**: 以前に作成した言語リソース。
3. 言語リソースの選択を促すメッセージが表示され<u>ない</u>場合は、すでに別の言語リソースが割り当てられている可能性があります。この場合は、以下の操作を行ってください。
    1. ページ上部のバーで、「**Settings (&#9881;)**」 (設定) ボタンをクリックします。
    2. 「**Settings**」 (設定) ページで「**Resources**」 (リソース) タブを選択します。
    3. 作成した言語リソースを選択し、「**Switch resource**」 (リソースの切り替え) をクリックします。
    4. ページ上部の「**Language Studio**」をクリックして、Language Studio のホーム ページに戻ります。
4. ポータルの上部にある「**Create new**」 (新規作成) メニューで、「**Conversational language understanding**」 (会話型言語理解) を選択します。
5. 「**Create a project**」 (プロジェクトの作成) ダイアログ ボックスの「**Choose project type**」 (プロジェクトの種類を選択) ページで、「**Conversation**」 (対話) を選択し、「**Next**」 (次へ) をクリックします。
6. 「**Enter basic information**」 (基本情報の入力) ページで、次の詳細を入力してから「**Next**」 (次へ) をクリックします:
    - **名前**: `Clock`
    - **説明**: `Natural language clock`
    - **主言語の発話**: 英語
    - **プロジェクトで複数の言語を有効にしますか?**: *未選択*
7. 「**Review and finish** (確認と完了) ページで、「**Create**」 (作成) をクリックします。

## 意図を作成する

新しいプロジェクトでは、最初にいくつかの意図を定義します。

> **ヒント**: プロジェクトで作業しているときにヒントが表示された場合は、ヒントを読んで「**Got it**」 (了解) をクリックして閉じるか、「**Skip all**」 (すべてスキップ) をクリックします。

1. 「**Build schema**」 (スキーマの構築) ページの「**Intents**」 (意図) タブで「**&#65291; Add**」 (追加) を選択し、**GetTime** という名前の新しい意図を作成します。
2. 新しい **GetTime** 意図をクリックして編集し、ユーザー入力の例として次の発話を追加します:

    `what is the time?`

    `what's the time?`

    `what time is it?`

    `tell me the time`

3. これらの発話を追加したら、「**Save changes**」 (変更の保存) をクリックして「**Build schema**」 (スキーマの構築) ページに戻ります。

4. 次の発話を含む **GetDay** という名前の新しい意図を追加します:

    `what day is it?`

    `what's the day?`

    `what is the day today?`

    `what day of the week is it?`

5. これらの発話の追加と保存を行ったら、「**Build schema**」 (スキーマの構築) ページに戻り、次の発話を含む **GetDate** という名前の別の新しい意図を追加します。

    `what date is it?`

    `what's the date?`

    `what is the date today?`

    `what's today's date?`

6. これらの発話の追加と保存を行い、発話ページの **GetDate** フィルターをクリアすると、すべての意図のすべての発話が表示されます。

## モデルのトレーニングとテストを行う

意図をいくつか追加したので、言語モデルをトレーニングして、ユーザー入力から正しく予測できるかどうかを確認しましょう。

1. 左側のペインで、「**Train model**」 (モデルをトレーニングする) ページを選択し、新しいモデルをトレーニングするオプションを選択します。「**Clock**」という名前を付け、トレーニング時に評価を実行するオプションが選択されるようにします。「**Train**」 (トレーニング) をクリックしてモデルをトレーニングします。
2. トレーニングが完了したら (時間がかかる場合があります)、「**View model details**」 (モデルの詳細を表示) ページを表示して「**Clock**」モデルを選択します。次に、全体的および意図ごとの評価メトリック (*適合率*、*再現率*、*F1 スコア*) と、トレーニング時に実施した評価によって生成された*混同行列*を表示します (サンプル発話数が少ないため、すべての意図が結果に含まれない場合があることに注意してください)。

    >**注**: 評価メトリックの詳細については、[ドキュメント](https://docs.microsoft.com/azure/cognitive-services/language-service/conversational-language-understanding/concepts/evaluation-metrics)を参照してください。

3. 「**Deploy model**」(モデルのデプロイ) で、「**Clock**」モデルを選択し、デプロイします。　 これには時間がかかる場合があります。
4. モデルがデプロイされたら、「**Test model**」 (モデルのテスト) ページで「**Clock**」モデルを選択します。
5. 次のテキストを入力し、「**Run the test**」 (テストの実行) をクリックします。

    `what's the time now?`

    返された結果を確認します。予測された意図 (**GetTime**である必要があります) と、予測された意図に対してモデルが計算した確率を示す信頼スコアが含まれていることに注意してください。「JSON」タブには、それぞれの潜在的な意図の比較信頼度が表示されます (信頼度スコアが最も高いものが予測された意図です)。

6. テキスト ボックスをクリアし、次のテキストで別のテストを実行します。

    `tell me the time`

    もう一度、予測された意図と信頼スコアを確認します。

7. 次のテキストを試してみてください。

    `what's the day today?`

    うまくいけば、モデルは **GetDay** 意図を予測します。

## エンティティを追加する

これまで、意図にマップするいくつかの簡単な発話を定義しました。ほとんどの実際のアプリケーションには、より複雑な発話が含まれており、意図のコンテキストを増やすために、特定のデータ エンティティを抽出する必要があります。

### *学習済み*エンティティを追加する

最も一般的な種類のエンティティは*学習済み*エンティティであり、モデルは例に基づいてエンティティ値を識別することを学習します。

1. Language Studio の「**Build schema**」 (スキーマの構築) ページに戻り、「**Entities**」 (エンティティ) タブで「**&#65291; Add**」 (追加) を選択して新しいエンティティを追加します。
2. 「**Add an entity**」 (エンティティの追加) ダイアログ ボックスで、エンティティ名「**Location**」を入力し、「**Learned**」 (学習済み) が選択されていることを確認します。「**Add entity**」 (エンティティの追加) をクリックします。
3. **Location** エンティティを作成したら、「**Build schema**」 (スキーマの構築) ページに戻り、「**Intents**」 (意図) タブで **GetTime** 意図を選択します。
4. 次の新しい発話例を入力します。

    `what time is it in London?`

5. 発話が追加されたら、***London*** という単語を選択し、表示されるドロップダウン リストで「**Location**」を選択して、"London" が場所の例であることを示します。
6. 別の発話例を追加します。

    `Tell me the time in Paris?`

7. 発話が追加されたら、***Paris*** という単語を選択し、それを **Location** エンティティにマップします。
8. 別の発話例を追加します。

    `what's the time in New York?`

9. 発話が追加されたら、***New York*** という単語を選択し、それらを **Location** エンティティにマップします。

10. 「**Save changes**」 (変更の保存) をクリックして新しい発話を保存します。

### *リスト* エンティティを追加する

場合によっては、エンティティの有効な値を特定の用語と同義語のリストに制限できます。これは、アプリが発話内のエンティティのインスタンスを識別するのに役立ちます。

1. Language Studio の「**Build schema**」 (スキーマの構築) ページに戻り、「**Entities**」 (エンティティ) タブで「**&#65291; Add**」 (追加) を選択して新しいエンティティを追加します。
2. 「**Add an entity**」 (エンティティの追加) ダイアログ ボックスで、エンティティ名「**Weekday**」を入力し、「**List**」エンティティ タイプを選択します。「**Add entity**」 (エンティティの追加) をクリックします。
3. **Weekday** エンティティのページの「**List**」セクションで、「**&#65291; Add new list**」 (新しいリストの追加) をクリックします。次に、次の値とシノニムを入力し、「**Save**」 (保存) をクリックします。

    | 値 | シノニム|
    |-------------------|---------|
    | sunday | sun |

4. 前の手順を繰り返して、以下のリスト コンポーネントを追加します。

    | 値 | シノニム|
    |-------------------|---------|
    | Monday | Mon |
    | Tuesday | Tue, Tues |
    | Wednesday | Wed, Weds |
    | Thursday | Thur, Thurs |
    | Friday | Fri |
    | Saturday | Sat |

5. 「**Build schema**」 (スキーマの構築) ページに戻り、「**Intents**」 (意図) タブで **GetDate** 意図を選択します。
6. 次の新しい発話例を入力します。

    `what date was it on Saturday?`

7. 発話が追加されたら、***Saturday*** という単語を選択し、表示されるドロップダウン リストで「**Weekday**」を選択します。
8. 別の発話例を追加します。

    `what date will it be on Friday?`

9. 発話が追加されたら、**Friday** を **Weekday** エンティティにマップします。

10. 別の発話例を追加します。

    `what will the be on Thurs?`

11. 発話が追加されたら、**Thurs** を **Weekday** エンティティにマップします。

12. 「**Save changes**」 (変更の保存) をクリックして新しい発話を保存します。

### *作成済み*エンティティを追加する

Language サービスは、会話型アプリケーションでよく使われる、*作成済み*エンティティのセットを提供します。

1. Language Studio の「**Build schema**」 (スキーマの構築) ページに戻り、「**Entities**」 (エンティティ) タブで「**&#65291; Add**」 (追加) を選択して新しいエンティティを追加します。
2. 「**Add an entity**」 (エンティティの追加) ダイアログ ボックスで、エンティティ名「**Date**」を入力し、「**prebuilt**」エンティティ タイプを選択します。「**Add entity**」 (エンティティの追加) をクリックします。
3. **Date** エンティティのページの「**Prebuilt**」セクションで、「**&#65291; Add new prebuilt**」 (新しい作成済みの追加) をクリックします。
4. 「**Select prebuilt**」 (作成済みの選択) リストで、「**DateTime**」を選択して「**Save**」 (保存) をクリックします。
5. 「**Build schema**」 (スキーマの構築) ページに戻り、「**Intents**」 (意図) タブで **GetDay** 意図を選択します。
6. 次の新しい発話例を入力します。

    `what day was 01/01/1901?`

7. 発話が追加されたら、***01/01/1901*** を選択し、表示されるドロップダウン リストで「**Date**」を選択します。
8. 別の発話例を追加します。

    `what day will it be on Dec 31st 2099?`

9. 発話が追加されたら、**Dec 31st 2099** を **Date** エンティティにマップします。

10. 「**Save changes**」 (変更の保存) をクリックして新しい発話を保存します。

### モデルを再トレーニングする

スキーマを変更したので、モードの再トレーニングと再テストを行う必要があります。

1. 「**Train model**」(モデルをトレーニングする) ページで、既存のモデルを上書きするオプションを選択し、**Clock** モデルを指定します。トレーニング時に評価を実行するオプションが選択されていることを確認し、「**Train**」 (トレーニング) をクリックしてモデルをトレーニングします。既存のモデルを上書きすることを確認します。
2. トレーニングが完了したら (時間がかかる場合があります)、「**View model details**」 (モデルの詳細を表示) ページを表示して「**Clock**」モデルを選択します。次に、全体的、エンティティごと、意図ごとの評価メトリック (*適合率*、*再現率*、*F1 スコア*) と、トレーニング時に実施した評価によって生成された*混同行列*を表示します (サンプル発話数が少ないため、すべての意図が結果に含まれない場合があることに注意してください)。
3. 「**Deploy model**」(モデルのデプロイ) で、「**Clock**」モデルを選択し、デプロイします。これには時間がかかる場合があります。
4. アプリがデプロイされたら、「**Test model**」 (モデルのテスト) ページで **Clock** モデルを選択し、次のテキストでテストします。

    `what's the time in Edinburgh?`

5. 返された結果を確認すると、**GetTime** 意図とテキスト値 "Edinburgh" を持つ **Location** エンティティが予測されるはずです。
6. 次の発話をテストしてみてください。

    `what time is it in Tokyo?`
    
    `what date is it on Friday?`

    `what's the date on Weds?`

    `what day was 01/01/2020?`

    `what day will Mar 7th 2030 be?`

## クライアント アプリでモデルを使用する

実際のプロジェクトでは、予測パフォーマンスに満足するまで、意図とエンティティを繰り返し改良し、再トレーニングして、再テストします。テストが完了し、予測パフォーマンスに満足したら、REST インターフェイスを呼び出してクライアント アプリで使用できます。この演習では、*curl* ユーティリティを使用して、モデルの REST エンドポイントを呼び出します。

1. Language Studio の「**Deploy model**」 (モデルのデプロイ) ページで、**Clock** モデルを選択します。次に、「**Get prediction URL**」(予測 URL の取得) をクリックします。
2. 「**Get prediction URL**」 (予測 URL の取得) ダイアログ ボックスには、予測エンドポイントの URL がサンプル リクエストとともに表示されます。このリクエストは、HTTP POST リクエストをエンドポイントに送信する **curl** コマンドで構成され、ヘッダーに Language リソースのキーを指定し、リクエスト データにクエリと言語を含めます。
3. サンプル リクエストをコピーし、任意のテキスト エディター (メモ帳など) に貼り付けます。
4. 次のプレースホルダーを置き換えます。
    - **YOUR_QUERY_HERE**: *What's the time in Sydney*
    - **QUERY_LANGUAGE_HERE**: *EN*

    コマンドは次のコードのようになります。

    ```
    curl -X POST "https://some-name.cognitiveservices.azure.com/language/:analyze-conversations?projectName=Clock&deploymentName=production&api-version=2021-11-01-preview" -H "Ocp-Apim-Subscription-Key: 0ab1c23de4f56..."  -H "Apim-Request-Id: 9zy8x76wv5u43...." -H "Content-Type: application/json" -d "{\"verbose\":true,\"query\":\"What's the time in Sydney?\",\"language\":\"EN\"}"
    ```

5. コマンド プロンプト (Windows) または Bash シェル (Linux/Mac) を開きます。
6. 編集した curl コマンドをコピーしてコマンド ライン インターフェイスに貼り付け、実行します。
7. 出力される JSON を確認します。これには次のような予測された意図とエンティティが含まれる必要があります。

    ```
    {"query":"What's the time in Sydney?","prediction":{"topIntent":"GetTime","projectKind":"conversation","intents":[{"category":"GetTime","confidenceScore":0.9998859},{"category":"GetDate","confidenceScore":9.8372206E-05},{"category":"GetDay","confidenceScore":1.5763446E-05}],"entities":[{"category":"Location","text":"Sydney","offset":19,"length":6,"confidenceScore":1}]}}
    ```

8. アプリから返された JSON 応答を確認します。これは、入力に対して予測された最高スコアの意図を示している必要があります (**GetTime** となっているはずです)。
9. curl コマンドのクエリを`What's today's date?`に変更して実行し、出力される JSONを確認します。
10. 次のクエリを試してみてください。

    `What day will Jan 1st 2050 be?`

    `What time is it in Glasgow?`

    `What date will next Monday be?`

## プロジェクトをエクスポートする

Language Studio を使用して言語理解モデルの開発とテストを行うことができますが、DevOps のソフトウェア開発プロセスでは、継続的インテグレーションと配信 (CI/CD) パイプラインに含めることができるプロジェクトのソース制御定義を維持する必要があります。コード スクリプトで Language REST API を使用してモデルの作成とトレーニングを行うことが*できます*。ただし、より簡単な方法は、ポータルを使用してモデル スキーマを作成し、それを別の Language サービス インスタンスでインポートおよび再トレーニングできる *[.json]* ファイルとしてエクスポートすることです。このアプローチにより、モデルの移植性と再現性を維持しながら、Language Studio ビジュアル インターフェイスの生産性のメリットを活用できます。

1. Language Studio の「**Projects**」 (プロジェクト) ページで、**Clock (Conversation)** プロジェクトを選択します。
2. 「**&#x2913; Export**」 (エクスポート) ボタンをクリックします。
3. 生成された **Clock.json** ファイルを任意の場所に保存します。
4. ダウンロードしたファイルを任意のコード エディター (例: Visual Studio Code) で開き、プロジェクトの JSON 定義を確認します。

## 詳細

**Language** サービスを使用して会話型言語理解ソリューションを作成する方法の詳細については、[Language サービスのドキュメント](https://docs.microsoft.com/azure/cognitive-services/language-service/conversational-language-understanding/overview)を参照してください。
